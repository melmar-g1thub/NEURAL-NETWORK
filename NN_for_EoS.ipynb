{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melmar-g1thub/NEURAL-NETWORK/blob/main/NN_for_EoS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNYF40UROgFk"
      },
      "source": [
        "2D MODEL: HS(DD2) neutron matter (with electrons):\n",
        "https://compose.obspm.fr/eos/2\n",
        "\n",
        "Inputs:\n",
        "1. n_B [fm-3]: (0.1E-11 0.1E+02)\n",
        "2. T [MeV]: (0.10000000E+00, 0.15848932E+03)\n",
        "3. Y_q → Constant (0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-w8OGEIEjpa"
      },
      "source": [
        "## PREPOCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmbviN_LEDIl"
      },
      "source": [
        "### UPLOADING LIBRARIES AND DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnwEDg8g6Yli"
      },
      "outputs": [],
      "source": [
        "!pip install skorch\n",
        "from skorch import NeuralNetRegressor\n",
        "from skorch.callbacks import EarlyStopping\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import seaborn as sns\n",
        "import random\n",
        "import itertools\n",
        "import json\n",
        "import joblib\n",
        "import time\n",
        "import ast\n",
        "import csv\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, RepeatedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, QuantileTransformer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import randint, loguniform\n",
        "from scipy.interpolate import griddata, SmoothBivariateSpline\n",
        "\n",
        "try:\n",
        "    from torch.amp import autocast\n",
        "except ImportError:\n",
        "    from torch.cuda.amp import autocast\n",
        "\n",
        "try:\n",
        "    from torch.amp import GradScaler\n",
        "except ImportError:\n",
        "    from torch.cuda.amp import GradScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bvz3RlXG6a4o"
      },
      "outputs": [],
      "source": [
        "# Load the data from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"/content/drive/My Drive/Colab Notebooks/data/\"\n",
        "\n",
        "# temperature and baryon number data\n",
        "eos_t = np.loadtxt(data_path + 'eos.t', skiprows=2)  # 81 values\n",
        "eos_nb = np.loadtxt(data_path + 'eos.nb', skiprows=2)  # 326 values\n",
        "eos_yq = np.zeros(len(eos_t))  # Constant value of 0\n",
        "\n",
        "# thermodynamic data\n",
        "thermo_data = np.loadtxt(data_path + 'eos.thermo', skiprows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0oZMlds8ySZ"
      },
      "outputs": [],
      "source": [
        "# Extract indices and thermodynamic properties\n",
        "indices = thermo_data[:, :3].astype(int)  # i_T, i_nb, i_Yq\n",
        "q_values = thermo_data[:, 3:5]  # Q1 (pressure) and Q2 (entropy)\n",
        "\n",
        "# Convert to zero-based index\n",
        "i_t = indices[:, 0] - 1\n",
        "i_nb = indices[:, 1] - 1\n",
        "\n",
        "# Ensure indices are valid, np.where() to get valid integer and not boolean\n",
        "valid_indices = np.where((i_t >= 0) & (i_t < len(eos_t)) & (i_nb >= 0) & (i_nb < len(eos_nb)))[0]\n",
        "T_valid = eos_t[i_t[valid_indices]]\n",
        "nb_valid = eos_nb[i_nb[valid_indices]]\n",
        "q_valid = q_values[valid_indices]\n",
        "\n",
        "logT = np.log10(T_valid)\n",
        "log_nb = np.log10(nb_valid)\n",
        "\n",
        "P_valid = q_valid[:, 0] * nb_valid\n",
        "S_valid = q_valid[:, 1] * nb_valid\n",
        "\n",
        "logP = np.log10(np.clip(P_valid, 1e-10, None))  # Protege contra log(0)\n",
        "logS = np.log10(np.clip(S_valid, 1e-10, None))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(q_valid[:,0]), max(q_valid[:,0]))\n",
        "print(min(q_valid[:,1]), max(q_valid[:,1]))\n",
        "print(min(nb_valid), max(nb_valid))"
      ],
      "metadata": {
        "id": "9YoSM427fGrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check original data to see its behaviour, skewdness, peaks....\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "axs[0, 0].hist(T_valid, bins=50, alpha=0.7, color=\"orange\")\n",
        "axs[0, 0].set_title('Original T')\n",
        "axs[0, 1].hist(nb_valid, bins=50, alpha=0.7, color=\"red\")\n",
        "axs[0, 1].set_title('Original nb')\n",
        "\n",
        "axs[1, 0].hist(P_valid , bins=50, alpha=0.7, color=\"green\")\n",
        "axs[1, 0].set_title('Original P')\n",
        "axs[1, 1].hist(S_valid, bins=50, alpha=0.7, color=\"blue\")\n",
        "axs[1, 1].set_title('Original S')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Original Data', y=1.02, fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S5jLoER2mJV3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_save_path = \"/content/drive/My Drive/Colab Notebooks/TFG_NN_FINAL/PLOTS\"\n",
        "os.makedirs(plot_save_path, exist_ok=True)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot logQ1 vs nb\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(log_nb, logS, alpha=0.6, s=10, color='blue')\n",
        "plt.xlabel(\"log10(nb)\")\n",
        "plt.ylabel(\"log10(S)\")\n",
        "plt.title(\"log(S) vs log(nb)\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot logP vs nb\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(log_nb, logP, alpha=0.6, s=10, color='green')\n",
        "plt.xlabel(\"log10(nb)\")\n",
        "plt.ylabel(\"log10(P)\")\n",
        "plt.title(\"logP vs log(nb)\")\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(plot_save_path, 'logP_logS_vs_lognb.png'), dpi=300, bbox_inches='tight')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "USqkrM0xvk6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMVe24dVD_qx"
      },
      "outputs": [],
      "source": [
        "# Filter central 90%\n",
        "T_q05, T_q95 = np.quantile(logT, [0.05, 0.95])\n",
        "nb_q05, nb_q95 = np.quantile(log_nb, [0.05, 0.95])\n",
        "mask = (logT >= T_q05) & (logT <= T_q95) & \\\n",
        "       (log_nb >= nb_q05) & (log_nb <= nb_q95)\n",
        "\n",
        "T_values = logT[mask]\n",
        "nb_values = log_nb[mask]\n",
        "P_values = logP[mask]\n",
        "S_values = logS[mask]\n",
        "\n",
        "inputs = np.vstack([T_values, nb_values]).T\n",
        "outputs = np.vstack([P_values, S_values]).T\n",
        "\n",
        "print(\"Initial inputs shape (before splitting/scaling):\", inputs.shape)\n",
        "print(\"Initial outputs shape (before splitting/scaling):\", outputs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH3C6V5s481H"
      },
      "outputs": [],
      "source": [
        "# 1. Histograms for individual features\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.histplot(inputs[:, 0], kde=True, bins=50, color='skyblue')\n",
        "plt.title('Distribution of log10(Temperature)')\n",
        "plt.xlabel('log10(T)')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.histplot(inputs[:, 1], kde=True, bins=50, color='lightcoral')\n",
        "plt.title('Distribution of log10(Baryon Number)')\n",
        "plt.xlabel('log10(nb)')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.histplot(outputs[:, 0], kde=True, bins=50, color='lightgreen')\n",
        "plt.title('Distribution of log10(Pressure)')\n",
        "plt.xlabel('log10(P)')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.histplot(outputs[:, 1], kde=True, bins=50, color='orchid')\n",
        "plt.title('Distribution of log10(Entropy)')\n",
        "plt.xlabel('log10(S)')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Distributions of Log-Transformed EoS Features (After 90% Filter)', y=1.02, fontsize=16)\n",
        "plt.savefig(os.path.join(plot_save_path, 'distributions_log_features.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjk3NtU86J7f"
      },
      "outputs": [],
      "source": [
        "# 2D Histogram / Density Plot for Input Parameters (T vs nb)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.hist2d(inputs[:, 0], inputs[:, 1], bins=50, cmap='viridis')\n",
        "plt.colorbar(label='Count')\n",
        "plt.xlabel('log10(T)')\n",
        "plt.ylabel('log10(nb)')\n",
        "plt.title('2D Distribution of Input Parameters (T vs nb)')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.savefig(os.path.join(plot_save_path, '2d_input_distribution.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.kdeplot(x=inputs[:, 0], y=inputs[:, 1], fill=True, cmap='viridis', levels=20)\n",
        "plt.xlabel('log10(T)')\n",
        "plt.ylabel('log10(nb)')\n",
        "plt.title('2D Density Plot of Input Parameters (T vs nb)')\n",
        "plt.savefig(os.path.join(plot_save_path, '2d_density_plot.png'), dpi=300, bbox_inches='tight')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWwpA8rzEv7Z"
      },
      "source": [
        "From the histograms we check:\n",
        "1. Uniform distributions with approximatly the same number of counts across their range\n",
        "2. Gaussian or close behaviour\n",
        "3. Skedness\n",
        "\n",
        "Stratification of inputs will not be required if they show 1 or 2 and after splitting and normalization their distributions are still representative of this behaviour on the EoS.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juq6pWTCEF-G"
      },
      "source": [
        "### PREPARATION OF DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbbVZf7mNQUr"
      },
      "source": [
        "Normalization of the files needs to be performed AFTER it's been divided in the train-validation-test sets!\n",
        "Because if we perform it before it causes:\n",
        "- Global Statistics: normalization process calculates these statistics (mean, std, min, max) using all the data points, including those in what will eventually become your test set.\n",
        "- Unfair Advantage: training set's scaled values are influenced by the statistics of the test set. This means your model indirectly \"sees\" information about the test data during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNqsYRobwyv9"
      },
      "outputs": [],
      "source": [
        "# 1. Split the data\n",
        "# First split: 80% train, 20% temp (for validation/test)\n",
        "in_train, in_temp, out_train, out_temp = train_test_split(\n",
        "    inputs, outputs, test_size=0.20, random_state=42, shuffle=True)\n",
        "\n",
        "# Second split: From the 20% temp, split it into 15% validation and 5% test\n",
        "in_val, in_test, out_val, out_test = train_test_split(\n",
        "    in_temp, out_temp, test_size=0.25, random_state=42, shuffle=True)\n",
        "\n",
        "print(f\"Train samples: {len(in_train)}\")\n",
        "print(f\"Validation samples: {len(in_val)}\")\n",
        "print(f\"Test samples: {len(in_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_GdiW4nN3Sj"
      },
      "source": [
        "Fit the Scaler ONLY on the Training Data, this calculates the necessary scaling parameters (mean, std, min, max) exclusively from the training distribution.\n",
        "\n",
        "Then, we apply transform() to the test and validation data, using the same fitted scaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zoHqiko96rK"
      },
      "outputs": [],
      "source": [
        "# 2. Normalization\n",
        "scaler_T = StandardScaler()\n",
        "scaler_nb = StandardScaler()\n",
        "scaler_P =  QuantileTransformer(output_distribution='normal', n_quantiles=1000, subsample=1_000_000, random_state=42)\n",
        "scaler_S = QuantileTransformer(output_distribution='normal', n_quantiles=1000, subsample=1_000_000, random_state=42)\n",
        "\n",
        "# StandardScaler:\tGaussian-like distribution, improves convergence with activation functions\n",
        "# MinMaxScaler: Best when we want normalized plots or comparisons, may want to clip/clamp outputs easily and care about scaled MAE/MSE\n",
        "# QuantileTransformer: Optimal for high skedness, transforming into Gaussian\n",
        "\n",
        "# We fit the scaler ONLY ON TRAINING SET\n",
        "def fit_train_scaler(tensor, scaler):\n",
        "  return scaler.fit_transform(tensor.reshape(-1, 1))\n",
        "\n",
        "# Then we simply apply the transformation to validation and test set\n",
        "def apply_scaler(tensor, scaler):\n",
        "  return scaler.transform(tensor.reshape(-1, 1))\n",
        "\n",
        "### INPUTS ###\n",
        "in_T_train_scaled = fit_train_scaler(in_train[:, 0], scaler_T)\n",
        "in_nb_train_scaled = fit_train_scaler(in_train[:, 1], scaler_nb)\n",
        "\n",
        "in_T_val_scaled = apply_scaler(in_val[:, 0], scaler_T)\n",
        "in_nb_val_scaled = apply_scaler(in_val[:, 1], scaler_nb)\n",
        "in_T_test_scaled = apply_scaler(in_test[:, 0], scaler_T)\n",
        "in_nb_test_scaled = apply_scaler(in_test[:, 1], scaler_nb)\n",
        "\n",
        "# Recombine inputs for each set\n",
        "in_train_processed = np.hstack((in_T_train_scaled, in_nb_train_scaled))\n",
        "in_val_processed = np.hstack((in_T_val_scaled, in_nb_val_scaled))\n",
        "in_test_processed = np.hstack((in_T_test_scaled, in_nb_test_scaled))\n",
        "\n",
        "\n",
        "### OUTPUTS ###\n",
        "out_P_train_scaled = fit_train_scaler(out_train[:, 0], scaler_P)\n",
        "out_S_train_scaled = fit_train_scaler(out_train[:, 1], scaler_S)\n",
        "\n",
        "out_P_val_scaled = apply_scaler(out_val[:, 0], scaler_P)\n",
        "out_S_val_scaled = apply_scaler(out_val[:, 1], scaler_S)\n",
        "out_P_test_scaled = apply_scaler(out_test[:, 0], scaler_P)\n",
        "out_S_test_scaled = apply_scaler(out_test[:, 1], scaler_S)\n",
        "\n",
        "out_train_processed = np.hstack((out_P_train_scaled, out_S_train_scaled))\n",
        "out_val_processed = np.hstack((out_P_val_scaled, out_S_val_scaled))\n",
        "out_test_processed = np.hstack((out_P_test_scaled, out_S_test_scaled))\n",
        "\n",
        "\n",
        "# Check the shapes of the input and output arrays\n",
        "print(\"Training: inputs shape:\", in_train_processed.shape)  # (number_of_samples, 2)\n",
        "print(\"Training: Outputs shape:\", out_train_processed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc2wfr3D-Rgo"
      },
      "outputs": [],
      "source": [
        "# Visualizing the normalization for TRAINING\n",
        "# Visualize normalization for Input Features (T and nb)\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "axs[0, 0].hist(in_train[:, 0], bins=50, alpha=0.7, color=\"orange\")\n",
        "axs[0, 0].set_title('Original log10(T)')\n",
        "axs[0, 1].hist(in_train_processed[:, 0], bins=50, alpha=0.7, color=\"darkorange\")\n",
        "axs[0, 1].set_title('Normalized log10(T)')\n",
        "\n",
        "axs[1, 0].hist(in_train[:,1], bins=50, alpha=0.7)\n",
        "axs[1, 0].set_title('Original log10(nb)')\n",
        "axs[1, 1].hist(in_train_processed[:, 1], bins=50, alpha=0.7, color='darkblue')\n",
        "axs[1, 1].set_title('Normalized log10(nb)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Input Data: Original vs. Normalized (Training Set)', y=1.02, fontsize=16)\n",
        "plt.savefig(os.path.join(plot_save_path, 'normalization_training_input.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Visualize normalization for Output Features (Q1/Pressure and Q2/Entropy)\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "axs[0, 0].hist(out_train[:,0], bins=50, alpha=0.7, color=\"green\")\n",
        "axs[0, 0].set_title('Original log10(P)')\n",
        "axs[0, 1].hist(out_train_processed[:, 0], bins=50, alpha=0.7, color=\"darkgreen\")\n",
        "axs[0, 1].set_title('Normalized log10(P)')\n",
        "\n",
        "axs[1, 0].hist(out_train[:,1], bins=50, alpha=0.7, color=\"red\")\n",
        "axs[1, 0].set_title('Original log10(S)')\n",
        "axs[1, 1].hist(out_train_processed[:, 1], bins=50, alpha=0.7, color=\"darkred\")\n",
        "axs[1, 1].set_title('Normalized log10(S)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Output Data: Original vs. Normalized (Training Set)', y=1.02, fontsize=16)\n",
        "plt.savefig(os.path.join(plot_save_path, 'normalization_training_output.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKewoLDyRZWy"
      },
      "outputs": [],
      "source": [
        "# Visualizing the normalization for VALIDATION\n",
        "# Visualize normalization for Input Features (T and nb)\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "axs[0, 0].hist(in_val[:, 0], bins=50, alpha=0.7, color=\"orange\")\n",
        "axs[0, 0].set_title('Original log10(T)')\n",
        "axs[0, 1].hist(in_val_processed[:, 0], bins=50, alpha=0.7, color=\"darkorange\")\n",
        "axs[0, 1].set_title('Normalized log10(T)')\n",
        "\n",
        "axs[1, 0].hist(in_val[:,1], bins=50, alpha=0.7)\n",
        "axs[1, 0].set_title('Original log10(nb)')\n",
        "axs[1, 1].hist(in_val_processed[:, 1], bins=50, alpha=0.7, color='darkblue')\n",
        "axs[1, 1].set_title('Normalized log10(nb)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Input Data: Original vs. Normalized (Validation Set)', y=1.02, fontsize=16)\n",
        "plt.savefig(os.path.join(plot_save_path, 'normalization_val_input.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Visualize normalization for Output Features (Q1/Pressure and Q2/Entropy)\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "axs[0, 0].hist(out_val[:,0], bins=50, alpha=0.7, color=\"green\")\n",
        "axs[0, 0].set_title('Original log10(P)')\n",
        "axs[0, 1].hist(out_val_processed[:, 0], bins=50, alpha=0.7, color=\"darkgreen\")\n",
        "axs[0, 1].set_title('Normalized log10(P)')\n",
        "\n",
        "axs[1, 0].hist(out_val[:,1], bins=50, alpha=0.7, color=\"red\")\n",
        "axs[1, 0].set_title('Original log10(S)')\n",
        "axs[1, 1].hist(out_val_processed[:, 1], bins=50, alpha=0.7, color=\"darkred\")\n",
        "axs[1, 1].set_title('Normalized log10(S)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Output Data: Original vs. Normalized (Validation Set)', y=1.02, fontsize=16)\n",
        "plt.savefig(os.path.join(plot_save_path, 'normalization_val_output.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNUS2Tu9_M-o"
      },
      "outputs": [],
      "source": [
        "# Visualizing the normalization for TESTING\n",
        "# Visualize normalization for Input Features (T and nb)\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "axs[0, 0].hist(in_test[:, 0], bins=50, alpha=0.7, color=\"orange\")\n",
        "axs[0, 0].set_title('Original log10(T)')\n",
        "axs[0, 1].hist(in_test_processed[:, 0], bins=50, alpha=0.7, color=\"darkorange\")\n",
        "axs[0, 1].set_title('Normalized log10(T)')\n",
        "\n",
        "axs[1, 0].hist(in_test[:,1], bins=50, alpha=0.7)\n",
        "axs[1, 0].set_title('Original log10(nb)')\n",
        "axs[1, 1].hist(in_test_processed[:, 1], bins=50, alpha=0.7, color='darkblue')\n",
        "axs[1, 1].set_title('Normalized log10(nb)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Input Data: Original vs. Normalized (Testing Set)', y=1.02, fontsize=16)\n",
        "plt.savefig(os.path.join(plot_save_path, 'normalization_testing_input.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Visualize normalization for Output Features (Q1/Pressure and Q2/Entropy)\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "axs[0, 0].hist(out_test[:,0], bins=50, alpha=0.7, color=\"green\")\n",
        "axs[0, 0].set_title('Original log10(P)')\n",
        "axs[0, 1].hist(out_test_processed[:, 0], bins=50, alpha=0.7, color=\"darkgreen\")\n",
        "axs[0, 1].set_title('Normalized log10(P)')\n",
        "\n",
        "axs[1, 0].hist(out_test[:,1], bins=50, alpha=0.7, color=\"red\")\n",
        "axs[1, 0].set_title('Original log10(S)')\n",
        "axs[1, 1].hist(out_test_processed[:, 1], bins=50, alpha=0.7, color=\"darkred\")\n",
        "axs[1, 1].set_title('Normalized log10(S)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Output Data: Original vs. Normalized (Testing Set)', y=1.02, fontsize=16)\n",
        "plt.savefig(os.path.join(plot_save_path, 'normalization_testing_output.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3cheUZe67n7"
      },
      "outputs": [],
      "source": [
        "# 3. Convert data to PyTorch tensors\n",
        "in_train_tensor = torch.FloatTensor(in_train_processed)\n",
        "out_train_tensor = torch.FloatTensor(out_train_processed)\n",
        "in_test_tensor = torch.FloatTensor(in_test_processed)\n",
        "out_test_tensor = torch.FloatTensor(out_test_processed)\n",
        "in_val_tensor = torch.FloatTensor(in_val_processed)\n",
        "out_val_tensor = torch.FloatTensor(out_val_processed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MF1X6L8Khs4"
      },
      "source": [
        "## DEFINE NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViE1VNNsLJ-Q"
      },
      "outputs": [],
      "source": [
        "class Interpolation(nn.Module):\n",
        "    def __init__(self, in_size, out_size, hidden_layer_sizes, dropout, activation):\n",
        "        super(Interpolation, self).__init__()\n",
        "        self.dropout_rate = dropout\n",
        "        self.activation = activation() # Skorch passes the class, so we instantiate it\n",
        "\n",
        "        layers = []\n",
        "        current_in_size = in_size\n",
        "\n",
        "        # Dynamically build hidden layers\n",
        "        for hidden_size in hidden_layer_sizes:\n",
        "            layers.append(nn.Linear(current_in_size, hidden_size))\n",
        "            layers.append(self.activation)\n",
        "            if self.dropout_rate > 0:\n",
        "                layers.append(nn.Dropout(self.dropout_rate))\n",
        "            current_in_size = hidden_size\n",
        "\n",
        "        # Output layer (linear for regression)\n",
        "        layers.append(nn.Linear(current_in_size, out_size))\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chvUlGvsEmsr"
      },
      "source": [
        "## RANDOM SEARCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP7hdEKMwABJ"
      },
      "source": [
        "#### Random Search - Scikit Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD_Gp1kIEyxx"
      },
      "source": [
        "The main challenge lies in bridging scikit-learn's RandomizedSearchCV with PyTorch nn.Module.\n",
        "- RandomizedSearchCV expects a scikit-learn estimator, which is a class that implements fit(), predict(), and potentially score().\n",
        "- Interpolation(nn.Module) is a PyTorch model, not directly a scikit-learn estimator.\n",
        "\n",
        "We'll do this with ` skorch ` where `NeuralNetRegressor`provides its own trainig loop. It also implements early stopping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t78FDRghFdBx"
      },
      "source": [
        "We'll also be logging the parameters and models in order to:\n",
        "- Compare all runs\n",
        "- Track randomness/reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h1JZ9L93HWN"
      },
      "outputs": [],
      "source": [
        "# Define the Search Space for the Randomly-searched parameters\n",
        "param_distributions = {\n",
        "    'module__hidden_layer_sizes': [(256, 128), (128, 64), (128, 64, 32), (64, 128, 64), (64, 64, 64)],\n",
        "    'module__activation': [nn.ReLU, nn.LeakyReLU, nn.ELU, nn.SiLU],\n",
        "    'module__dropout': [0.1, 0.2, 0.4, 0.5],\n",
        "    'lr': np.logspace(-4, -2, 20),\n",
        "    'batch_size': [32, 64, 128, 256],\n",
        "}\n",
        "\n",
        "# Defined hyperparameters\n",
        "input_size = 2  # baryon number and temperature\n",
        "output_size = 2 # Q1 and Q2 in eos.thermo\n",
        "\n",
        "n_iterations = 40\n",
        "epochs = 200\n",
        "patience = 25\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Aditional metrics\n",
        "def prediction_variance(y_true, y_pred):\n",
        "    return np.var(y_pred)\n",
        "\n",
        "r2_scorer = make_scorer(r2_score, greater_is_better=True)\n",
        "var_scorer = make_scorer(prediction_variance, greater_is_better=True)\n",
        "\n",
        "# Define the model\n",
        "# Skorch wrapper\n",
        "model_estimator = NeuralNetRegressor(\n",
        "    module=Interpolation,\n",
        "    module__in_size=input_size,\n",
        "    module__out_size=output_size,\n",
        "    max_epochs=epochs,\n",
        "    lr=0.01,  # Will be overridden during random search\n",
        "    batch_size=64, #Likewise\n",
        "    optimizer=torch.optim.Adam,\n",
        "    criterion=nn.MSELoss,\n",
        "    callbacks=[EarlyStopping(monitor='valid_loss', patience=patience)],\n",
        ")\n",
        "\n",
        "# Define the CrossValidation\n",
        "cv = RepeatedKFold(n_splits=3, n_repeats=2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPhhbFj0AqSy"
      },
      "source": [
        "RandomSearchCV implements Cross Validations KFold, RepeatedKFold is recommended for regression tasks\n",
        "\n",
        "It also includes a scoring, the metric must be maximizing: better models result in larger scores\n",
        "For regression, a negative error measure (‘neg_mean_absolute_error‘) makes values closer to zero to represent less prediction error by the model.\n",
        "\n",
        "Once defined, the search is performed by calling the fit() function and providing a dataset used to train and evaluate model hyperparameter combinations using cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9_sJ4OuEH2L"
      },
      "outputs": [],
      "source": [
        "def save_random_search_results(search_obj, name_prefix=\"logP_logS_search\"):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    base_dir = \"/content/drive/My Drive/Colab Notebooks/Random\"\n",
        "    exp_dir = os.path.join(base_dir, f\"{name_prefix}_{timestamp}\")\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "\n",
        "    # CSV + JSON\n",
        "    results_df = pd.DataFrame(search_obj.cv_results_)\n",
        "    results_df.to_csv(os.path.join(exp_dir, \"results_full.csv\"), index=False)\n",
        "\n",
        "    def safe_serialize(obj):\n",
        "        if isinstance(obj, dict):\n",
        "            return {k: safe_serialize(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, list):\n",
        "            return [safe_serialize(v) for v in obj]\n",
        "        elif isinstance(obj, tuple):\n",
        "            return tuple(safe_serialize(v) for v in obj)\n",
        "        elif isinstance(obj, (int, float, str, bool)) or obj is None:\n",
        "            return obj\n",
        "        else:\n",
        "            return str(obj)  # Convertir cualquier otro tipo a string\n",
        "\n",
        "    with open(os.path.join(exp_dir, \"results_full.json\"), \"w\") as f:\n",
        "        json.dump(safe_serialize(search_obj.cv_results_), f, indent=2)\n",
        "\n",
        "    joblib.dump(search_obj.best_estimator_, os.path.join(exp_dir, \"best_model.pkl\"))\n",
        "    with open(os.path.join(exp_dir, \"best_params.json\"), \"w\") as f:\n",
        "        json.dump({k: str(v) for k, v in search_obj.best_params_.items()}, f, indent=2)\n",
        "\n",
        "    return exp_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "afNMYqjxwG5o"
      },
      "outputs": [],
      "source": [
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model_estimator,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=n_iterations,\n",
        "    cv=cv,\n",
        "    scoring={\n",
        "        'mean_mse': 'neg_mean_squared_error',\n",
        "        'r2': r2_scorer,\n",
        "        'var_pred': var_scorer\n",
        "    },\n",
        "    refit='r2',  # interpolar y capturar relaciones reales con R² es más exigente.\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Convert combined train+val data to PyTorch tensors for the search (NumPy for RandomizedSearchCV)\n",
        "x_train_val = np.concatenate((in_train_processed, in_val_processed), axis=0).astype(np.float32)\n",
        "y_train_val = np.concatenate((out_train_processed, out_val_processed), axis=0).astype(np.float32)\n",
        "\n",
        "print(\"Starting Randomized Search with Skorch...\")\n",
        "start_time = time.time()\n",
        "random_search.fit(x_train_val, y_train_val)\n",
        "end_time = time.time()\n",
        "elapsed = end_time - start_time\n",
        "minutes, seconds = divmod(elapsed, 60)\n",
        "print(f\"\\n Randomized Search complete.\")\n",
        "print(f\"Total time: {int(minutes)} min {int(seconds)} sec\")\n",
        "\n",
        "save_random_search_results(random_search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Pf5tZleygyrR"
      },
      "outputs": [],
      "source": [
        "# Log results\n",
        "logfile = '/content/drive/My Drive/Colab Notebooks/Random/results_full.csv'\n",
        "log_dir = os.path.dirname(logfile)\n",
        "os.makedirs(log_dir, exist_ok=True) # Ensure directory exists\n",
        "\n",
        "results_df = pd.read_csv(logfile)\n",
        "\n",
        "# Clean up and rename columns for clarity\n",
        "columns_to_log = [\n",
        "    'param_module__hidden_layer_sizes',\n",
        "    'param_lr',\n",
        "    'param_module__dropout',\n",
        "    'param_module__activation',\n",
        "    'param_batch_size',\n",
        "    'rank_test_mean_mse',\n",
        "    'rank_test_r2',\n",
        "    'rank_test_var_pred',\n",
        "    'mean_fit_time',\n",
        "    'std_fit_time',\n",
        "    'mean_test_mean_mse',\n",
        "    'mean_test_r2',\n",
        "    'mean_test_var_pred'\n",
        "]\n",
        "\n",
        "df_filtered = results_df[columns_to_log].copy()\n",
        "\n",
        "df_filtered.rename(columns={\n",
        "    'param_module__hidden_layer_sizes': 'hidden_layer_sizes',\n",
        "    'param_lr': 'learning_rate',\n",
        "    'param_module__dropout': 'dropout',\n",
        "    'param_module__activation': 'activation_fn',\n",
        "    'param_batch_size': 'batch_size',\n",
        "    'mean_test_mean_mse': 'mean_neg_mse',\n",
        "    'mean_test_r2': 'mean_r2',\n",
        "    'mean_test_var_pred': 'mean_var'\n",
        "}, inplace=True)\n",
        "\n",
        "df_filtered['mean_mse'] = -df_filtered['mean_neg_mse'] # Convert to positive MSE\n",
        "\n",
        "df_filtered.to_csv(logfile, index=False)\n",
        "print(f\"\\nAll search results saved to: {logfile}\")\n",
        "\n",
        "# Summarize best result\n",
        "print('\\n--- Best Result ---')\n",
        "print('Best cross-validation score (R2): %s' % random_search.best_score_) # Use random_search here, not result_df\n",
        "print('Best Hyperparameters: %s' % random_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H6K5b2h-ztb"
      },
      "source": [
        "#### EVALUATION OF RANDOM SEARCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFYzW5elfYTR"
      },
      "source": [
        "PAIRPLOT is a multi-plot grid that shows the relationship between each pair of variables in a dataset. It includes:\n",
        "- Scatter plots for every variable vs every other variable.\n",
        "- Distributions for each variable on the diagonal.\n",
        "\n",
        "And it shows:\n",
        "1. Linear or nonlinear relationships (e.g., higher learning rate → higher MSE?)\n",
        "2. Clusters (e.g., some batch sizes perform consistently better?)\n",
        "3. Outliers (points that break patterns)\n",
        "4. Correlations (strong slopes in the scatter plots)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrPAaOwdYxVa"
      },
      "outputs": [],
      "source": [
        "plot_save_path = \"/content/drive/My Drive/Colab Notebooks/Random/Hyperparameters Analysis\"\n",
        "os.makedirs(plot_save_path, exist_ok=True)\n",
        "\n",
        "# Pairplot for comparing the different combinations of hyperparameters\n",
        "le_act = LabelEncoder()\n",
        "le_layer = LabelEncoder()\n",
        "\n",
        "df_filtered['activation_fn_str'] = df_filtered['activation_fn'].apply(lambda fn: fn if isinstance(fn, str) else fn.__name__)\n",
        "df_filtered['hidden_layer_str'] = df_filtered['hidden_layer_sizes'].astype(str)\n",
        "df_filtered['activation_fn_encoded'] = le_act.fit_transform(df_filtered['activation_fn_str'])\n",
        "df_filtered['hidden_layer_encoded'] = le_layer.fit_transform(df_filtered['hidden_layer_str'])\n",
        "\n",
        "# Set columns for pairplot\n",
        "pairplot_vars = ['learning_rate', 'dropout', 'batch_size', 'mean_mse']\n",
        "\n",
        "# Plot with activation_fn colored\n",
        "g = sns.pairplot(df_filtered, vars=pairplot_vars, hue='activation_fn_str', diag_kind='kde', corner='True')\n",
        "\n",
        "# Adjust legend title and position\n",
        "new_labels = ['ReLU', 'LeakyReLU']\n",
        "for t, l in zip(g._legend.texts, new_labels):\n",
        "    t.set_text(l)\n",
        "g._legend.set_title(\"Activation Function\")\n",
        "g._legend.set_bbox_to_anchor((0.6, 0.8))  # move it outside the plot if needed\n",
        "\n",
        "plt.suptitle(\"Pairplot of Hyperparameters vs MSE\", fontsize=16, y=1.02, x=0.4)\n",
        "plt.savefig(os.path.join(plot_save_path, 'MSE_pairplot_act_fn.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot with hidden_layers colored\n",
        "h = sns.pairplot(df_filtered, vars=pairplot_vars, hue='hidden_layer_str', diag_kind='kde', corner='True')\n",
        "h._legend.set_title(\"Hidden Layers Architecture\")\n",
        "h._legend.set_bbox_to_anchor((0.7, 0.8))\n",
        "plt.suptitle(\"Pairplot of Hyperparameters vs MSE\", fontsize=16, y=1.02)\n",
        "plt.savefig(os.path.join(plot_save_path, 'MSE_pairplot_hidden.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spr7ZW09lWnZ"
      },
      "outputs": [],
      "source": [
        "# Grouped boxplot\n",
        "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "palette = sns.color_palette(\"pastel\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(\n",
        "    data=df_filtered,\n",
        "    x='activation_fn_str',\n",
        "    y='mean_mse',\n",
        "    hue='hidden_layer_str',\n",
        "    palette=palette,\n",
        "    width=0.7,\n",
        "    linewidth=1.5,\n",
        "    fliersize=5,\n",
        "    dodge=True\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Activation Function\", fontsize=13)\n",
        "plt.ylabel(\"Mean MSE (CV)\", fontsize=13)\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.legend(title=\"Hidden Layers\", bbox_to_anchor=(1.02, 1), loc='upper left',\n",
        "           borderaxespad=0, prop={'size': 11}, title_fontsize=10)\n",
        "\n",
        "plt.title(\"Validation MSE by Activation and Hidden Layer Configuration\", fontsize=14)\n",
        "plt.savefig(os.path.join(plot_save_path, 'MSE_boxlot_act_hidden.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilw1n1YzZeBb"
      },
      "outputs": [],
      "source": [
        "# Heatmat of correlations\n",
        "corr_df = df_filtered[['learning_rate', 'dropout', 'batch_size',\n",
        "                         'activation_fn_encoded', 'hidden_layer_encoded', 'mean_mse']]\n",
        "\n",
        "corr_matrix = corr_df.corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True, cbar=True)\n",
        "plt.title(\"Heatmap of correlations between hyperparameters and MSE\")\n",
        "plt.tight_layout()\n",
        "#plt.savefig(os.path.join(plot_save_path, 'MSE_heatmap.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl_5mgSXROjI"
      },
      "outputs": [],
      "source": [
        "# Plot top5 optimal combinations ranked by metrics\n",
        "\n",
        "logfile = '/content/drive/My Drive/Colab Notebooks/Random/results_full.csv'\n",
        "log_dir = os.path.dirname(logfile)\n",
        "os.makedirs(log_dir, exist_ok=True) # Ensure directory exists\n",
        "\n",
        "df = pd.read_csv(logfile)\n",
        "\n",
        "top5_r2 = df.sort_values(by='rank_test_r2').head(5).copy()\n",
        "top5_mse = df.sort_values(by='rank_test_mean_mse').head(5).copy()\n",
        "top5_var = df.sort_values(by='rank_test_var_pred').head(5).copy()\n",
        "\n",
        "for df_sub in [top5_r2, top5_mse, top5_var]:\n",
        "    df_sub['config_label'] = df_sub.apply(\n",
        "        lambda row: f\"{row['hidden_layer_sizes']} | dr={row['dropout']} | batch={row['batch_size']} | lr={row['learning_rate']:.1e}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "# Plot Side-by-side\n",
        "fig, axs = plt.subplots(1, 3, figsize=(22, 6), sharey=False)\n",
        "\n",
        "# R²\n",
        "sns.barplot(x='mean_r2', y='config_label', data=top5_r2, palette='crest', ax=axs[0])\n",
        "axs[0].set_title(\"Top 5 - R²\")\n",
        "axs[0].set_xlabel(\"Mean R² (Validation)\")\n",
        "axs[0].grid(axis='x', linestyle='--', alpha=0.6)\n",
        "\n",
        "# MSE\n",
        "sns.barplot(x='mean_mse', y='config_label', data=top5_mse, palette='crest', ax=axs[1])\n",
        "axs[1].set_title(\"Top 5 - MSE\")\n",
        "axs[1].set_xlabel(\"Mean MSE (Validation)\")\n",
        "axs[1].grid(axis='x', linestyle='--', alpha=0.6)\n",
        "\n",
        "# Variace\n",
        "sns.barplot(x='mean_var', y='config_label', data=top5_var, palette='crest', ax=axs[2])\n",
        "axs[2].set_title(\"Top 5 - Predicted Variance\")\n",
        "axs[2].set_xlabel(\"Mean Predicted Variance\")\n",
        "axs[2].grid(axis='x', linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.tight_layout()\n",
        "output_file = os.path.join(plot_save_path, \"top5_hyperparameter_comparison.png\")\n",
        "plt.savefig(output_file, dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTbSE7TZbev2"
      },
      "source": [
        "RANDOM FOREST measures how much each input variable (hyperparameter) contributes to reducing the error in the forest:\n",
        "- For each tree in the forest, it checks how much each feature reduces the MSE when it’s used to split a node.\n",
        "- Then it averages these reductions over all trees, giving you one score per hyperparameter.\n",
        "\n",
        "The more it reduces the error → the more “important” it is deemed to be.\n",
        "\n",
        "> We used a Random Forest to estimate the relative importance of each hyperparameter in determining the model's validation MSE. Although not a formal SHAP analysis, this approach provides a fast and intuitive proxy to guide hyperparameter tuning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uemvA4X6ZtVf"
      },
      "outputs": [],
      "source": [
        "# SHAP graph\n",
        "# RandomizedSearchCV no entrena un modelo con interpretabilidad directa como un árbol,\n",
        "# usaremos RandomForestRegressor para estimar la importancia relativa de cada hiperparámetro sobre el MSE\n",
        "\n",
        "X_forest = df_filtered[['learning_rate', 'dropout', 'batch_size', 'activation_fn_encoded', 'hidden_layer_encoded']]\n",
        "Y_forest = df_filtered['mean_r2']\n",
        "\n",
        "# Train Forest model to stimate relevance of each parameter\n",
        "rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
        "rf.fit(X_forest, Y_forest)\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "feature_names = X_forest.columns\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=importances, y=feature_names, palette='viridis')\n",
        "plt.title(\"Impact of hyperparameters on R2 (RandomForest estimation)\")\n",
        "plt.xlabel(\"Relative importance\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(plot_save_path, 'R2_randomforest.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb3q75CSE8rG"
      },
      "source": [
        "## FINAL EVALUATION OF MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epZ2G4d9pIcr"
      },
      "source": [
        "### RETRAIN TOP MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3-LGE4GCG_R"
      },
      "source": [
        "We're gonna evaluate top 3 best combinations from Random Search for longer number of runs and evaluate its results and metrics.\n",
        "\n",
        "We'll make use of mixed precision with `autocast()` and `GradScaler`  for speeding up training on GPUs and reducing memory usage, especially for larger models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OK3IkpzAb8C"
      },
      "outputs": [],
      "source": [
        "# Get 3 top configurations from csv\n",
        "logfile = '/content/drive/My Drive/Colab Notebooks/Random/results_full.csv'\n",
        "log_dir = os.path.dirname(logfile)\n",
        "os.makedirs(log_dir, exist_ok=True) # Ensure directory exists\n",
        "\n",
        "df = pd.read_csv(logfile)\n",
        "top3_configs = df.sort_values(by='rank_test_r2').head(3)\n",
        "print(top3_configs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMInBUz6EMcJ"
      },
      "source": [
        "We're gonna save the results for each configuration:Colab Notebooks/07.06/final_top3_models/\n",
        "- best trained model as `model_top{i}.pth`\n",
        "- final metrics and hyperparamerters as `config.json`\n",
        "- losses as `train_losses.npy` and `val_losses.np` for later plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilb_Eeh0ANPn"
      },
      "outputs": [],
      "source": [
        "# Create path to save results from training\n",
        "results = []\n",
        "base_path = \"/content/drive/My Drive/Colab Notebooks/Random\"\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "input_size = 2\n",
        "output_size = 2\n",
        "\n",
        "# Loop for going onto the 3 configurations\n",
        "for i, (_, row) in enumerate(top3_configs.iterrows(), start=1):\n",
        "    print(f\"\\n Training configuration #{i}...\")\n",
        "\n",
        "    # Hyperparameters from the csv\n",
        "    dropout = row['dropout']\n",
        "    lr = row['learning_rate']\n",
        "    batch = int(row['batch_size'])\n",
        "    hidden = ast.literal_eval(row['hidden_layer_sizes']) # Safer parsing\n",
        "    if isinstance(row['activation_fn'], str) and row['activation_fn'].startswith(\"<class \"):\n",
        "        act_name = row['activation_fn'].split(\"'\")[1].split('.')[-1]  # e.g. 'ReLU'\n",
        "    else:\n",
        "        act_name = row['activation_fn']\n",
        "    act_fn = getattr(nn, act_name)\n",
        "\n",
        "    print(dropout, lr, batch, hidden, act_fn)\n",
        "\n",
        "    # Set dataloaders\n",
        "    train_dataset = TensorDataset(in_train_tensor, out_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
        "\n",
        "    # Inicialize the model, optimizer and loss\n",
        "    model = Interpolation(input_size, output_size, hidden, dropout, act_fn).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    scaler = GradScaler() # Mixed precision\n",
        "\n",
        "    # Early stopping\n",
        "    epochs = 600\n",
        "    patience = 60\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    ##############################################################\n",
        "    #TRAINING AND VALIDATION LOOP\n",
        "    ##############################################################\n",
        "    train_losses, val_losses = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "        all_train_preds = []\n",
        "\n",
        "        # Batch training\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            with autocast(device_type=device.type):\n",
        "                train_pred = model(xb)\n",
        "                train_loss = loss_fn(train_pred, yb)\n",
        "            # Backward pass and optimization\n",
        "            scaler.scale(train_loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            epoch_train_loss += train_loss.item() * xb.size(0)\n",
        "            all_train_preds.append(train_pred.detach().cpu())\n",
        "\n",
        "        train_losses.append(epoch_train_loss  / len(train_loader.dataset))\n",
        "        train_pred = torch.cat(all_train_preds, dim=0).numpy()\n",
        "\n",
        "        # Validation (no batching)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            with autocast(device_type=device.type):\n",
        "                val_pred = model(in_val_tensor.to(device))\n",
        "                val_loss = loss_fn(val_pred, out_val_tensor.to(device))\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss.item()\n",
        "            torch.save(model.state_dict(), os.path.join(base_path, f\"model_top{i}.pth\"))\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch:03d} | Train Loss: {train_losses[-1]:.9f} | Val Loss: {val_losses[-1]:.9f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    duration = (end_time - start_time) / 60\n",
        "    print(f\"Finished config #{i} in {duration:.1f} minutes with best val loss: {best_val_loss:.9f}\")\n",
        "\n",
        "    # Save configuration and loss values\n",
        "    run_path = os.path.join(base_path, f\"top{i}\")\n",
        "    os.makedirs(run_path, exist_ok=True)\n",
        "\n",
        "    with open(os.path.join(run_path, \"config.json\"), \"w\") as f:\n",
        "        json.dump({\n",
        "            'hidden_layer_sizes': hidden,\n",
        "            'activation_fn': row['activation_fn'],\n",
        "            'dropout': dropout,\n",
        "            'learning_rate': lr,\n",
        "            'batch_size': batch,\n",
        "            'best_val_loss': best_val_loss,\n",
        "            'duration_minutes': duration\n",
        "        }, f, indent=2)\n",
        "\n",
        "    np.save(os.path.join(run_path, \"train_losses.npy\"), np.array(train_losses))\n",
        "    np.save(os.path.join(run_path, \"val_losses.npy\"), np.array(val_losses))\n",
        "\n",
        "    np.save(os.path.join(run_path, \"train_pred.npy\"), np.array(train_pred))\n",
        "    np.save(os.path.join(run_path, \"val_pred.npy\"), np.array(val_pred.cpu().detach().numpy()))\n",
        "\n",
        "    # PLOTTING LOSS CURVES\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss (MSE)\")\n",
        "    plt.yscale(\"linear\")  # puedes usar \"log\" si prefieres logarítmico\n",
        "    plt.gca().yaxis.set_major_formatter(ticker.ScalarFormatter(useMathText=True))\n",
        "    plt.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))  # fuerza notación científica\n",
        "    plt.title(f\"Loss Curves - Top {i}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(run_path, \"loss_curve.png\"), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    ##############################################################\n",
        "    # EVALUATION MODE\n",
        "    ##############################################################\n",
        "    # Load the best model state dictionary\n",
        "    model.load_state_dict(torch.load(os.path.join(base_path, f\"model_top{i}.pth\")))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with autocast(device_type=device.type):\n",
        "            test_pred = model(in_test_tensor.to(device))\n",
        "            test_loss = loss_fn(test_pred, out_test_tensor.to(device))\n",
        "\n",
        "    with open(os.path.join(run_path, \"test_metrics.json\"), \"w\") as f:\n",
        "        json.dump({'test_loss': test_loss.item()}, f, indent=2)\n",
        "    print(f\" Final Test Loss for config #{i}: {test_loss.item():.9f}\")\n",
        "    np.save(os.path.join(run_path, \"test_pred.npy\"), np.array(test_pred.cpu().detach().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3ovVc3-pO-T"
      },
      "source": [
        "### PLOT LOSSES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVpYkwSElymL"
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "# FOLDER final_top3_models\n",
        "#######################3####################\n",
        "base_path = \"/content/drive/My Drive/Colab Notebooks/Random\"\n",
        "top_models = ['top1', 'top2', 'top3']\n",
        "\n",
        "# Gráfico completo (desde epoch 0)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "for idx, model in enumerate(top_models):\n",
        "    run_path = os.path.join(base_path, model)\n",
        "    train_losses = np.load(os.path.join(run_path, \"train_losses.npy\"))\n",
        "    val_losses = np.load(os.path.join(run_path, \"val_losses.npy\"))\n",
        "\n",
        "    epochs = np.arange(len(train_losses))\n",
        "\n",
        "    ax = axes[idx]\n",
        "    ax.plot(epochs, train_losses, label='Train Loss', color='green')\n",
        "    ax.plot(epochs, val_losses, label='Validation Loss', color='pink')\n",
        "    ax.set_title(f\"Model {model.upper()}\")\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_yscale(\"log\")\n",
        "    ax.yaxis.set_major_formatter(ticker.ScalarFormatter(useMathText=True))\n",
        "    ax.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    if idx == 0:\n",
        "        ax.set_ylabel(\"Loss (MSE)\")\n",
        "    ax.legend()\n",
        "\n",
        "plt.suptitle(\"Loss Curves for Top 3 Configurations (from epoch 0)\", fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.savefig(os.path.join(base_path, \"loss_curves_total_top3.png\"), dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Gráfico zoom (desde epoch 50)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "start_epoch = 50\n",
        "for idx, model in enumerate(top_models):\n",
        "    run_path = os.path.join(base_path, model)\n",
        "    train_losses = np.load(os.path.join(run_path, \"train_losses.npy\"))\n",
        "    val_losses = np.load(os.path.join(run_path, \"val_losses.npy\"))\n",
        "\n",
        "\n",
        "    epochs = np.arange(start_epoch, len(train_losses))\n",
        "    train_trimmed = train_losses[start_epoch:]\n",
        "    val_trimmed = val_losses[start_epoch:]\n",
        "\n",
        "    ax = axes[idx]\n",
        "    ax.plot(epochs, train_trimmed, label='Train Loss', color='green')\n",
        "    ax.plot(epochs, val_trimmed, label='Validation Loss', color='pink')\n",
        "    ax.set_title(f\"Model {model.upper()}\")\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_yscale(\"log\")\n",
        "    ax.yaxis.set_major_formatter(ticker.ScalarFormatter(useMathText=True))\n",
        "    ax.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    if idx == 0:\n",
        "        ax.set_ylabel(\"Loss (MSE)\")\n",
        "    ax.legend()\n",
        "\n",
        "plt.suptitle(f\"Loss Curves for Top 3 Configurations (from epoch {start_epoch})\", fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.savefig(os.path.join(base_path, \"loss_curves_zoom_top3.png\"), dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Solo para el modelo top1\n",
        "model = 'top1'\n",
        "base_path = \"/content/drive/My Drive/Colab Notebooks/Random\"\n",
        "run_path = os.path.join(base_path, model)\n",
        "\n",
        "train_losses = np.load(os.path.join(run_path, \"train_losses.npy\"))\n",
        "val_losses = np.load(os.path.join(run_path, \"val_losses.npy\"))\n",
        "\n",
        "epochs = np.arange(len(train_losses))\n",
        "start_epoch = 50\n",
        "epochs_zoom = np.arange(start_epoch, len(train_losses))\n",
        "\n",
        "# Crear figura con dos subgráficos\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
        "\n",
        "# Gráfico completo\n",
        "axes[0].plot(epochs, train_losses, label='Train Loss', color='green')\n",
        "axes[0].plot(epochs, val_losses, label='Validation Loss', color='pink')\n",
        "axes[0].set_title(\"TOP1 - From Epoch 0\")\n",
        "axes[0].set_xlabel(\"Epoch\")\n",
        "axes[0].set_ylabel(\"Loss (MSE)\")\n",
        "axes[0].set_yscale(\"log\")\n",
        "axes[0].yaxis.set_major_formatter(ticker.ScalarFormatter(useMathText=True))\n",
        "axes[0].ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
        "axes[0].grid(True, linestyle='--', alpha=0.6)\n",
        "axes[0].legend()\n",
        "\n",
        "# Gráfico desde época 50\n",
        "axes[1].plot(epochs_zoom, train_losses[start_epoch:], label='Train Loss', color='green')\n",
        "axes[1].plot(epochs_zoom, val_losses[start_epoch:], label='Validation Loss', color='pink')\n",
        "axes[1].set_title(\"TOP1 - From Epoch 50\")\n",
        "axes[1].set_xlabel(\"Epoch\")\n",
        "axes[1].set_yscale(\"log\")\n",
        "axes[1].yaxis.set_major_formatter(ticker.ScalarFormatter(useMathText=True))\n",
        "axes[1].ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
        "axes[1].grid(True, linestyle='--', alpha=0.6)\n",
        "axes[1].legend()\n",
        "\n",
        "plt.suptitle(\"Loss Curves for Model TOP1\", fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.savefig(os.path.join(base_path, \"loss_top1_dual.png\"), dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a0NOkbBvRz6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Kb_ALprfrxw"
      },
      "source": [
        "### MODEL'S STATISTICS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6qQe1CPS8z0"
      },
      "source": [
        "To evaluate the accuracy of the neural network interpolation, we computed mean squared error (MSE), mean absolute error (MAE), and coefficient of determination (R²) for both pressure (P) and entropy (S) across the training, validation, and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjA2mHkkoowD"
      },
      "outputs": [],
      "source": [
        "top_path = \"/content/drive/My Drive/Colab Notebooks/Random/top1\"\n",
        "os.makedirs(top_path, exist_ok=True)\n",
        "\n",
        "train_predictions = np.load(os.path.join(top_path, \"train_pred.npy\"))\n",
        "val_predictions   = np.load(os.path.join(top_path, \"val_pred.npy\"))\n",
        "test_predictions  = np.load(os.path.join(top_path, \"test_pred.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtBbIY0wYVk3"
      },
      "outputs": [],
      "source": [
        "def evaluate_actual_predictions(predictions, real_output, scaler_q1, scaler_q2):\n",
        "    if isinstance(predictions, torch.Tensor):\n",
        "        pred_np = predictions.cpu().detach().numpy()\n",
        "    else:\n",
        "        pred_np = predictions\n",
        "\n",
        "    # We splitted before normalizing, however the predictions need to be inverse transformed\n",
        "    P_true = 10 ** real_output[:, 0]\n",
        "    S_true = 10 ** real_output[:, 1]\n",
        "    P_pred = 10 ** scaler_q1.inverse_transform(pred_np[:, 0].reshape(-1, 1)).flatten()\n",
        "    S_pred = 10 **  scaler_q2.inverse_transform(pred_np[:, 1].reshape(-1, 1)).flatten()\n",
        "\n",
        "    results = {\n",
        "    'P_MSE': mean_squared_error(P_true, P_pred),\n",
        "    'P_MAE': mean_absolute_error(P_true, P_pred),\n",
        "    'P_R2': r2_score(P_true, P_pred),\n",
        "    'S_MSE': mean_squared_error(S_true, S_pred),\n",
        "    'S_MAE': mean_absolute_error(S_true, S_pred),\n",
        "    'S_R2': r2_score(S_true, S_pred),\n",
        "    }\n",
        "\n",
        "    print(f\"Pressure P [MeV/fm³]\")\n",
        "    print(f\"  MSE : {results['P_MSE']:.4e}\")\n",
        "    print(f\"  MAE : {results['P_MAE']:.4e}\")\n",
        "    print(f\"  R²  : {np.abs(results['P_R2']):.4f}\")\n",
        "\n",
        "    print(f\"Entropy S [1/fm³]\")\n",
        "    print(f\"  MSE : {results['S_MSE']:.4e}\")\n",
        "    print(f\"  MAE : {results['S_MAE']:.4e}\")\n",
        "    print(f\"  R²  : {np.abs(results['S_R2']):.4f}\")\n",
        "\n",
        "    return results, P_true, P_pred, S_true, S_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od08gObbc5KS"
      },
      "outputs": [],
      "source": [
        "print(f\" --- Metrics for training data set ---\")\n",
        "train_metrics, P_train_true, P_train_pred, S_train_true, S_train_pred = evaluate_actual_predictions(\n",
        "     predictions = train_predictions,\n",
        "     real_output = out_train,\n",
        "     scaler_q1 = scaler_P,\n",
        "     scaler_q2 = scaler_S)\n",
        "\n",
        "print(f\"\\n --- Metrics for validation data set ---\")\n",
        "val_metrics, P_val_true, P_val_pred, S_val_true, S_val_pred = evaluate_actual_predictions(\n",
        "    predictions = val_predictions,\n",
        "    real_output = out_val,\n",
        "     scaler_q1 = scaler_P,\n",
        "     scaler_q2 = scaler_S)\n",
        "\n",
        "print(f\"\\n --- Metrics for evaluation data set ---\")\n",
        "test_metrics, P_test_true, P_test_pred, S_test_true, S_test_pred = evaluate_actual_predictions(\n",
        "    predictions = test_predictions,\n",
        "    real_output = out_test,\n",
        "     scaler_q1 = scaler_P,\n",
        "     scaler_q2 = scaler_S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWrSUFjmflDK"
      },
      "source": [
        "### VISUALIZE RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-gnasMWjYj"
      },
      "source": [
        "We study the models interpolation power by plotting Predicted vs Tabulated logaritmic values for P and S. We hope data to be on top of x == y line, meaning the model has interpolated accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHmLpwgWky_V"
      },
      "outputs": [],
      "source": [
        "# ONLY PRESSURE COMPARISION\n",
        "min_P_train = min(P_train_true.min(), P_train_pred.min())\n",
        "max_P_train = max(P_train_true.max(), P_train_pred.max())\n",
        "\n",
        "min_P_val = min(P_val_true.min(), P_val_pred.min())\n",
        "max_P_val = max(P_val_true.max(), P_val_pred.max())\n",
        "\n",
        "min_P_test = min(P_test_true.min(), P_test_pred.min())\n",
        "max_P_test = max(P_test_true.max(), P_test_pred.max())\n",
        "\n",
        "# Scatter Plot for actual vs predicted\n",
        "plt.figure(figsize=(18, 7))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(P_train_true, P_train_pred, alpha=0.6, label='Training Data', color='limegreen')\n",
        "plt.plot([min_P_train, max_P_train], [min_P_train, max_P_train], 'r--', label='Ideal line')\n",
        "plt.xlabel('Tabulated Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.title('Training Data for Pressure: True vs Predicted')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(P_val_true, P_val_pred, alpha=0.6, label='Validation Data', color='green')\n",
        "plt.plot([min_P_val, max_P_val], [min_P_val, max_P_val], 'r--', label='Ideal line')\n",
        "plt.xlabel('Tabulated Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.title('Validation Data for Pressure: True vs Predicted')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(P_test_true, P_test_pred, alpha=0.6, label='Test Data', color='darkslategray')\n",
        "plt.plot([min_P_test, max_P_test], [min_P_test, max_P_test], 'r--', label='Ideal line')\n",
        "plt.xlabel('Tabulated Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.title('Test Data for Pressure: True vs Predicted')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(base_path, \"pred_real_P.png\"), dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU1MD2ySmOlv"
      },
      "outputs": [],
      "source": [
        "# ONLY ENTROPY COMPARISINO\n",
        "# Scatter Plot for actual vs predicted\n",
        "plt.figure(figsize=(16, 7))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(S_train_true, S_train_pred, alpha=0.6, label='Training Data', color='lightblue')\n",
        "plt.plot([min(S_train_true), max(S_train_true)], [min(S_train_true), max(S_train_true)], 'r--', label='Ideal line')\n",
        "plt.xlabel('Tabulated Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.title('Training Data for Entropy: True vs Predicted')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(S_val_true, S_val_pred, alpha=0.6, label='Validation Data', color='blue')\n",
        "plt.plot([min(S_val_true), max(S_val_true)], [min(S_val_true), max(S_val_true)], 'r--', label='Ideal line')\n",
        "plt.xlabel('Tabulated Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.title('Validation Data for Entropy: True vs Predicted')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(S_test_true, S_test_pred, alpha=0.5, label='Test Data', color='darkblue')\n",
        "plt.plot([min(S_test_true), max(S_test_true)], [min(S_test_true), max(S_test_true)], 'r--', label='Ideal line')\n",
        "plt.xlabel('Tabulated Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.title('Test Data for Entropy: True vs Predicted')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(base_path, \"pred_real_S.png\"), dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3D surface plot to visualize how good interpolation is on a global scale of all output data"
      ],
      "metadata": {
        "id": "4IGNJCPu3Q_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeklRlPAJey1"
      },
      "outputs": [],
      "source": [
        "# 3D Surface Plot for q1 (Pressure)\n",
        "T_test = scaler_T.inverse_transform(in_test[:, 0].reshape(-1, 1)).flatten()\n",
        "nb_test = scaler_nb.inverse_transform(in_test[:, 1].reshape(-1, 1)).flatten()\n",
        "\n",
        "print(nb_test.shape), print(T_test.shape)\n",
        "print(P_test_true.shape), print(P_test_pred.shape)\n",
        "\n",
        "print(\"Plotting predictions and original test data\")\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "ax1.scatter(T_test, nb_test, P_test_true, label='Tabulated P values', alpha=0.5)\n",
        "ax1.scatter(T_test, nb_test, P_test_pred, label='Interpolated P values', alpha=0.5)\n",
        "ax1.set_xlabel('Temperature')\n",
        "ax1.set_ylabel('Baryon Number')\n",
        "ax1.set_zlabel('Pressure')\n",
        "ax1.legend()\n",
        "\n",
        "# 3D Surface Plot for q2 (Entropy)\n",
        "ax2 = fig.add_subplot(122, projection='3d')\n",
        "ax2.scatter(T_test, nb_test, S_test_true, label='Tabulated S values', alpha=0.5)\n",
        "ax2.scatter(T_test, nb_test, S_test_pred, label='Interpolated S values', alpha=0.5)\n",
        "ax2.set_xlabel('Temperature')\n",
        "ax2.set_ylabel('Baryon Number')\n",
        "ax2.set_zlabel('Entropy')\n",
        "ax2.legend()\n",
        "\n",
        "plt.savefig(os.path.join(base_path, \"pred_real_3d_plot.png\"), dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-i2rGp6FD0G"
      },
      "source": [
        "Residual(True−Predicted) plots are incredibly insightful for regression models. Plotting residuals against the true values (or predicted values) can reveal patterns of error:\n",
        "\n",
        "- Homoscedasticity: residuals should be randomly scattered around zero.\n",
        "If they form a cone shape, it suggests that the model's error varies with the magnitude of the prediction.\n",
        "- Bias: If residuals are consistently positive or negative in a certain range, it indicates bias (systematic underprediction or overprediction).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0k125TUE8sx"
      },
      "outputs": [],
      "source": [
        "# Residual plot for P\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 7), sharey=True)\n",
        "fig.suptitle('Residuals Plot for Pressure Prediction', fontsize=16)\n",
        "\n",
        "# Training set\n",
        "residuals_train_P = P_train_true - P_train_pred\n",
        "axes[0].scatter(P_train_pred, residuals_train_P, alpha=0.6, color='limegreen')\n",
        "axes[0].axhline(y=0, color='r', linestyle='--')\n",
        "axes[0].set_xlabel('Predicted Training Values')\n",
        "axes[0].set_ylabel('Residuals (True - Predicted)')\n",
        "axes[0].set_title('Training Set')\n",
        "\n",
        "# Validation set\n",
        "residuals_val_P = P_val_true - P_val_pred\n",
        "axes[1].scatter(P_val_pred, residuals_val_P, alpha=0.6, color='green')\n",
        "axes[1].axhline(y=0, color='r', linestyle='--')\n",
        "axes[1].set_xlabel('Predicted Validation Values')\n",
        "axes[1].set_title('Validation Set')\n",
        "\n",
        "# Testing set\n",
        "residuals_test_P = P_test_true - P_test_pred\n",
        "axes[2].scatter(P_test_pred, residuals_test_P, alpha=0.6, color='darkgreen')\n",
        "axes[2].axhline(y=0, color='r', linestyle='--')\n",
        "axes[2].set_xlabel('Predicted Testing Values')\n",
        "axes[2].set_title('Testing Set')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.savefig(os.path.join(base_path, \"residuals_plot_P.png\"), dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYxhv-Y_bnUf"
      },
      "outputs": [],
      "source": [
        "# Residual plot for S\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 7), sharey=True)\n",
        "fig.suptitle('Residuals Plot for Entropy Prediction', fontsize=16)\n",
        "\n",
        "# Training set\n",
        "residuals_train_S = S_train_true - S_train_pred\n",
        "axes[0].scatter(S_train_pred, residuals_train_S, alpha=0.6, color='royalblue')\n",
        "axes[0].axhline(y=0, color='r', linestyle='--')\n",
        "axes[0].set_xlabel('Predicted Training Values')\n",
        "axes[0].set_ylabel('Residuals (True - Predicted)')\n",
        "axes[0].set_title('Training Set')\n",
        "\n",
        "# Validation set\n",
        "residuals_val_S = S_val_true - S_val_pred\n",
        "axes[1].scatter(S_val_pred, residuals_val_S, alpha=0.6, color='cornflowerblue')\n",
        "axes[1].axhline(y=0, color='r', linestyle='--')\n",
        "axes[1].set_xlabel('Predicted Validation Values')\n",
        "axes[1].set_title('Validation Set')\n",
        "\n",
        "# Testing set\n",
        "residuals_test_S = S_test_pred - S_test_pred\n",
        "axes[2].scatter(S_test_true, residuals_test_S, alpha=0.6, color='midnightblue')\n",
        "axes[2].axhline(y=0, color='r', linestyle='--')\n",
        "axes[2].set_xlabel('Predicted Testing Values')\n",
        "axes[2].set_title('Testing Set')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.savefig(os.path.join(base_path, \"residuals_plot_S.png\"), dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzk_JqVDcVq9"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(24, 10), sharey='row')\n",
        "fig.suptitle('Residuals for Pressure and Entropy Predictions (Colored by nb)', fontsize=18)\n",
        "\n",
        "nb_train = 10 ** in_train[:, 1]\n",
        "nb_val = 10 ** in_val[:, 1]\n",
        "nb_test = 10 ** in_test[:, 1]\n",
        "\n",
        "# --- Pressure Residuals ---\n",
        "sc0 = axes[0, 0].scatter(P_train_true, P_train_true - P_train_pred, c=nb_train, cmap='viridis', alpha=0.6)\n",
        "axes[0, 0].axhline(0, color='red', linestyle='--')\n",
        "axes[0, 0].set_title('Training Set (P)')\n",
        "axes[0, 0].set_ylabel('Residuals P (True - Predicted)')\n",
        "\n",
        "sc1 = axes[0, 1].scatter(P_val_true, P_val_true - P_val_pred, c=nb_val, cmap='viridis', alpha=0.6)\n",
        "axes[0, 1].axhline(0, color='red', linestyle='--')\n",
        "axes[0, 1].set_title('Validation Set (P)')\n",
        "\n",
        "sc2 = axes[0, 2].scatter(P_test_true, P_test_true - P_test_pred, c=nb_test, cmap='viridis', alpha=0.6)\n",
        "axes[0, 2].axhline(0, color='red', linestyle='--')\n",
        "axes[0, 2].set_title('Testing Set (P)')\n",
        "\n",
        "# --- Entropy Residuals ---\n",
        "sc3 = axes[1, 0].scatter(S_train_true, S_train_true - S_train_pred, c=nb_train, cmap='viridis', alpha=0.6)\n",
        "axes[1, 0].axhline(0, color='red', linestyle='--')\n",
        "axes[1, 0].set_title('Training Set (S)')\n",
        "axes[1, 0].set_xlabel('Tabulated Training Values')\n",
        "axes[1, 0].set_ylabel('Residuals S (True - Predicted)')\n",
        "\n",
        "sc4 = axes[1, 1].scatter(S_val_true, S_val_true - S_val_pred, c=nb_val, cmap='viridis', alpha=0.6)\n",
        "axes[1, 1].axhline(0, color='red', linestyle='--')\n",
        "axes[1, 1].set_title('Validation Set (S)')\n",
        "axes[1, 1].set_xlabel('Tabulated Validation Values')\n",
        "\n",
        "sc5 = axes[1, 2].scatter(S_test_true, S_test_true - S_test_pred, c=nb_test, cmap='viridis', alpha=0.6)\n",
        "axes[1, 2].axhline(0, color='red', linestyle='--')\n",
        "axes[1, 2].set_title('Testing Set (S)')\n",
        "axes[1, 2].set_xlabel('Tabulated Testing Values')\n",
        "\n",
        "# Colorbar for nb\n",
        "cbar = fig.colorbar(sc5, ax=axes.ravel().tolist(), label='Baryon Density (nb)', shrink=0.95, pad=0.01)\n",
        "cbar.ax.set_ylabel('Baryon Density (nb)', rotation=270, labelpad=15)\n",
        "\n",
        "plt.tight_layout(rect=[0, 1.1, 1, 0.95])\n",
        "plt.savefig(os.path.join(base_path, \"residuals_combined_colored_by_nb.png\"), dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xARTwgmEuhj"
      },
      "source": [
        "## INTERPOLATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eJ4LspllM6q"
      },
      "source": [
        "Now that i've found a model that performs as hoped, the whole goal of my interpolation nn is interpolating from a tabulated EoS of Neutron Stars, where the known x variables are temperature (T) and baryon number (n_b) and the y variables are pressure (P) and Entropy (S).\n",
        "\n",
        "I do know the values of both the x and y variables because i take them from given tabulated EoS in compose archive. However, i need to prove that my interpolating algorithm is good, this means i should stick to a small region of my range and do an interpolation, taking lets say x_1 and x_3 that i do know and interpolating y_2 for x_2 that even if i also know both values i write a code as if i didn't, in order to prove if it interpolates well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CEnNfpVlN2M"
      },
      "source": [
        "1. Select Known Points:\n",
        "Let’s assume we have points (x_1) (T1, n1) and (x_3) (T3, n3) that we know, where (x_2) will be the intermediate point.\n",
        "Define (x_2) (T2, n2) within the range of the known points.\n",
        "\n",
        "2. Interpolation Procedure\n",
        "Treat the prediction for (x_2) (T2, n2) as an unknown during your actual interpolation process.\n",
        "During this phase, we use the model to predict (P_2) and (S_2).\n",
        "\n",
        "3. Evaluation\n",
        "Calculate the difference between predicted (P_2) and (S_2) from the model and the exact known values from the tabulated EoS.\n",
        "Metrics like Mean Absolute Error (MAE) or Mean Squared Error (MSE) to quantify how close the interpolated values are to the actual known values."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NN AND BSPLINE COMPARISION"
      ],
      "metadata": {
        "id": "MLsVgqWGToAI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B30207s6xoYl"
      },
      "outputs": [],
      "source": [
        "#######################################################\n",
        "# NN INTERPOLATION\n",
        "#######################################################\n",
        "def interpolation_test_nn(model, inputs_set, outputs_set, scaler_P, scaler_S, device, indices, save_dir):\n",
        "    model.eval()\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    metrics = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    def inv_log_scaled(values, scaler):\n",
        "      values = np.array(values).reshape(-1, 1)\n",
        "      return scaler.inverse_transform(values).flatten()\n",
        "\n",
        "    for i, center_index in enumerate(indices):\n",
        "        if center_index < 1 or center_index >= len(inputs_set) - 1:\n",
        "            continue\n",
        "\n",
        "        x1 = in_test[center_index - 1]\n",
        "        x2 = in_test[center_index]\n",
        "        x3 = in_test[center_index + 1]\n",
        "\n",
        "        y1 = out_test[center_index - 1]\n",
        "        y2_true = out_test[center_index]\n",
        "        y3 = out_test[center_index + 1]\n",
        "\n",
        "        x_tensor = torch.FloatTensor(x2).unsqueeze(0).to(device)\n",
        "        model_eval\n",
        "        with torch.no_grad():\n",
        "            y2_pred = model(x_tensor).cpu().numpy()[0]\n",
        "\n",
        "        # Denormalize\n",
        "        P_true = 10 ** np.array([y1[0], y2_true[0], y3[0]])\n",
        "        S_true = 10 ** np.array([y1[1], y2_true[1], y3[1]])\n",
        "        P_pred = 10 ** inv_log_scaled([y2_pred[0]], scaler_P)[0]\n",
        "        S_pred = 10 ** inv_log_scaled([y2_pred[1]], scaler_S)[0]\n",
        "\n",
        "        # Metrics\n",
        "        mse_P = mean_squared_error([P_true[1]], [P_pred])\n",
        "        mae_P = mean_absolute_error([P_true[1]], [P_pred])\n",
        "        mse_S = mean_squared_error([S_true[1]], [S_pred])\n",
        "        mae_S = mean_absolute_error([S_true[1]], [S_pred])\n",
        "\n",
        "        metrics.append({\n",
        "            \"method\": \"NN\",\n",
        "            \"index\": int(center_index),\n",
        "            \"mse_P\": mse_P,\n",
        "            \"mae_P\": mae_P,\n",
        "            \"mse_S\": mse_S,\n",
        "            \"mae_S\": mae_S\n",
        "        })\n",
        "\n",
        "        # Plot\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        x_labels = ['x1', 'x2', 'x3']\n",
        "        x_ticks = np.arange(3)\n",
        "\n",
        "        axs[0].plot(x_ticks, P_true, label='True P', marker='o', color='green')\n",
        "        axs[0].scatter(x_ticks[1], P_pred, label='Predicted P', marker='x', s=100, color='red')\n",
        "        axs[0].set_title('Pressure (P)')\n",
        "        axs[0].set_xticks(x_ticks)\n",
        "        axs[0].set_xticklabels(x_labels)\n",
        "        axs[0].grid(True)\n",
        "        axs[0].legend()\n",
        "\n",
        "        axs[1].plot(x_ticks, S_true, label='True S', marker='o', color='blue')\n",
        "        axs[1].scatter(x_ticks[1], S_pred, label='Predicted S', marker='x', s=100, color='orange')\n",
        "        axs[1].set_title('Entropy (S)')\n",
        "        axs[1].set_xticks(x_ticks)\n",
        "        axs[1].set_xticklabels(x_labels)\n",
        "        axs[1].grid(True)\n",
        "        axs[1].legend()\n",
        "\n",
        "        plt.suptitle(f\"NN Interpolation Triplet Test #{i+1} (Index {center_index})\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        filename = f\"NN_triplet_{i+1}_index_{center_index}.png\"\n",
        "        plt.savefig(os.path.join(save_dir, filename), dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    for m in metrics:\n",
        "        m[\"elapsed_sec\"] = elapsed\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH2Ev5DdyKng"
      },
      "outputs": [],
      "source": [
        "#######################################################\n",
        "# b-SPLINES INTERPOLATION\n",
        "#######################################################\n",
        "def interpolation_test_bspline(in_train, out_train, in_test, out_test, indices, save_dir):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    x = in_train[:, 0]\n",
        "    y = in_train[:, 1]\n",
        "    z_P = out_train[:, 0]\n",
        "    z_S = out_train[:, 1]\n",
        "\n",
        "    bspline_P = SmoothBivariateSpline(x, y, z_P, kx=3, ky=3)\n",
        "    bspline_S = SmoothBivariateSpline(x, y, z_S, kx=3, ky=3)\n",
        "\n",
        "    metrics = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, center_index in enumerate(indices):\n",
        "        if center_index < 1 or center_index >= len(in_test) - 1:\n",
        "            continue\n",
        "\n",
        "        gap=10\n",
        "\n",
        "        x1 = in_test[center_index - gap]\n",
        "        x2 = in_test[center_index]\n",
        "        x3 = in_test[center_index + gap]\n",
        "\n",
        "        y1 = out_test[center_index - gap]\n",
        "        y2_true = out_test[center_index]\n",
        "        y3 = out_test[center_index + gap]\n",
        "\n",
        "        # Predicions for middle point\n",
        "        P_pred_log = bspline_P.ev(x2[0], x2[1])\n",
        "        S_pred_log = bspline_S.ev(x2[0], x2[1])\n",
        "\n",
        "        # Inverse log transformation to get real phyisical values\n",
        "        P_true = 10 ** np.array([y1[0], y2_true[0], y3[0]])\n",
        "        S_true = 10 ** np.array([y1[1], y2_true[1], y3[1]])\n",
        "        P_pred = 10 ** P_pred_log\n",
        "        S_pred = 10 ** S_pred_log\n",
        "\n",
        "        # Metrics\n",
        "        mse_P = mean_squared_error([P_true[1]], [P_pred])\n",
        "        mae_P = mean_absolute_error([P_true[1]], [P_pred])\n",
        "        mse_S = mean_squared_error([S_true[1]], [S_pred])\n",
        "        mae_S = mean_absolute_error([S_true[1]], [S_pred])\n",
        "\n",
        "        metrics.append({\n",
        "            \"method\": \"B-Spline\",\n",
        "            \"index\": int(center_index),\n",
        "            \"mse_P\": mse_P,\n",
        "            \"mae_P\": mae_P,\n",
        "            \"mse_S\": mse_S,\n",
        "            \"mae_S\": mae_S\n",
        "        })\n",
        "\n",
        "        # Plot\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        x_labels = ['x1', 'x2', 'x3']\n",
        "        x_ticks = np.arange(3)\n",
        "\n",
        "        axs[0].plot(x_ticks, P_true, label='True P', marker='o', color='green')\n",
        "        axs[0].scatter(x_ticks[1], P_pred, label='Predicted P', marker='x', s=100, color='red')\n",
        "        axs[0].set_title('Pressure (P)')\n",
        "        axs[0].set_xticks(x_ticks)\n",
        "        axs[0].set_xticklabels(x_labels)\n",
        "        axs[0].grid(True)\n",
        "        axs[0].legend()\n",
        "        axs[0].ticklabel_format(axis='y', style='sci', scilimits=(-3, 3)) # Scientific notation for y-axis\n",
        "\n",
        "        axs[1].plot(x_ticks, S_true, label='True S', marker='o', color='blue')\n",
        "        axs[1].scatter(x_ticks[1], S_pred, label='Predicted S', marker='x', s=100, color='orange')\n",
        "        axs[1].set_title('Entropy (S)')\n",
        "        axs[1].set_xticks(x_ticks)\n",
        "        axs[1].set_xticklabels(x_labels)\n",
        "        axs[1].grid(True)\n",
        "        axs[1].legend()\n",
        "        axs[0].ticklabel_format(axis='y', style='sci', scilimits=(-3, 3)) # Scientific notation for y-axis\n",
        "\n",
        "        plt.suptitle(f\"B-Spline Interpolation Triplet Test #{i+1} (Index {center_index})\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        filename = f\"SPLINE_triplet_{i+1}_index_{center_index}.png\"\n",
        "        plt.savefig(os.path.join(save_dir, filename), dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    for m in metrics:\n",
        "        m[\"elapsed_sec\"] = elapsed\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_3QuXrYylRv"
      },
      "outputs": [],
      "source": [
        "def compare_results(metrics_nn, metrics_spline):\n",
        "    print(\"\\n--- COMPARE INTERPOLATION METHODS ---\")\n",
        "    time_nn = np.mean([m[\"elapsed_sec\"] for m in metrics_nn])\n",
        "    time_sp = np.mean([m[\"elapsed_sec\"] for m in metrics_spline])\n",
        "    print(f\"⏱️  Average timer per execution - NN: {time_nn:.2f}s | B-Spline: {time_sp:.2f}s\\n\")\n",
        "\n",
        "    print(\"Triplet | MSE_P (NN / BSpl) | MAE_P (NN / BSpl) | MSE_S (NN / BSpl) | MAE_S (NN / BSpl)\")\n",
        "    print(\"-\" * 75)\n",
        "\n",
        "    for i, (m_nn, m_sp) in enumerate(zip(metrics_nn, metrics_spline)):\n",
        "        print(f\"   {i+1}    | {m_nn['mse_P']:.2e} / {m_sp['mse_P']:.2e} |\"\n",
        "              f\" {m_nn['mae_P']:.2e} / {m_sp['mae_P']:.2e} |\"\n",
        "              f\" {m_nn['mse_S']:.2e} / {m_sp['mse_S']:.2e} |\"\n",
        "              f\" {m_nn['mae_S']:.2e} / {m_sp['mae_S']:.2e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the model and instantiate\n",
        "top_path = \"/content/drive/My Drive/Colab Notebooks/Random/top1\"\n",
        "config_path = os.path.join(top_path, \"config.json\")\n",
        "weights_path = os.path.join(top_path, \"model_top1.pth\")\n",
        "\n",
        "def load_activation_fn(activation_str):\n",
        "    activation_map = {\n",
        "        \"ReLU\": nn.ReLU,\n",
        "        \"LeakyReLU\": nn.LeakyReLU,\n",
        "        \"SiLU\": nn.SiLU\n",
        "    }\n",
        "\n",
        "    if \"LeakyReLU\" in activation_str:\n",
        "        return activation_map[\"LeakyReLU\"]\n",
        "    elif \"ReLU\" in activation_str:\n",
        "        return activation_map[\"ReLU\"]\n",
        "    elif \"SiLU\" in activation_str:\n",
        "        return activation_map[\"SiLU\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Activation function '{activation_str}' not recognized.\")\n",
        "\n",
        "def load_model_from_config(config_path, in_size, out_size):\n",
        "    with open(config_path, \"r\") as f:\n",
        "        config = json.load(f)\n",
        "    hidden_layer_sizes = config.get(\"hidden_layer_sizes\")\n",
        "    dropout = config.get(\"dropout\")\n",
        "    activation_str = config.get(\"activation_fn\")\n",
        "    activation_cls = load_activation_fn(activation_str)\n",
        "\n",
        "    model = Interpolation(in_size, out_size, hidden_layer_sizes, dropout, activation_cls)\n",
        "    return model\n",
        "\n",
        "in_size = 2\n",
        "out_size = 2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = load_model_from_config(config_path, in_size, out_size)\n",
        "model.load_state_dict(torch.load(weights_path, map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "# Same index for both\n",
        "N = len(in_test)\n",
        "np.random.seed(42)\n",
        "indices = np.sort(np.random.randint(50, N - 50, size=5))\n",
        "print(indices)\n",
        "\n",
        "dir_nn = \"/content/drive/My Drive/Colab Notebooks/Random/top1\"\n",
        "os.makedirs(dir_nn, exist_ok=True)\n",
        "dir_spl = \"/content/drive/My Drive/Colab Notebooks/Random/top1\"\n",
        "os.makedirs(dir_spl, exist_ok=True)"
      ],
      "metadata": {
        "id": "7wGtOpxncK9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWVpN2A6ywPu"
      },
      "outputs": [],
      "source": [
        "# 1. Interpolación con red neuronal\n",
        "metrics_nn = interpolation_test_nn(\n",
        "    model=model,\n",
        "    inputs_set=in_test,\n",
        "    outputs_set=out_test,\n",
        "    scaler_P=scaler_P,\n",
        "    scaler_S=scaler_S,\n",
        "    device=device,\n",
        "    indices=indices,\n",
        "    save_dir=dir_nn\n",
        ")\n",
        "for metric in metrics_nn:\n",
        "    print(metric)\n",
        "\n",
        "\n",
        "# 2. Interpolación con B-Spline\n",
        "metrics_spline = interpolation_test_bspline(\n",
        "    in_train=in_train,\n",
        "    out_train=out_train,\n",
        "    in_test=in_test,\n",
        "    out_test=out_test,\n",
        "    indices=indices,\n",
        "    save_dir=dir_spl\n",
        ")\n",
        "for metric in metrics_spline:\n",
        "    print(metric)\n",
        "\n",
        "# Guardar metrics\n",
        "save_dir = \"/content/drive/My Drive/Colab Notebooks/Random/top1\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "df_all = pd.DataFrame(metrics_nn + metrics_spline)\n",
        "csv_path = os.path.join(save_dir, \"interpolation_metrics_comparison.csv\")\n",
        "df_all.to_csv(csv_path, index=False)\n",
        "\n",
        "# 3. Comparar resultados\n",
        "compare_results(metrics_nn, metrics_spline)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NN LOCAL INTERPOLATION"
      ],
      "metadata": {
        "id": "XVH70u0qMj1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare triplets and train"
      ],
      "metadata": {
        "id": "C_Q3XlrkkAFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gap = 1\n",
        "# Training triplets\n",
        "in_train_triplets = torch.stack([\n",
        "    torch.cat((in_train_tensor[i - gap], in_train_tensor[i + gap]))\n",
        "    for i in range(gap, len(in_train_tensor) - gap)\n",
        "])\n",
        "out_train_targets = out_train_tensor[gap : len(out_train_tensor) - gap]\n",
        "\n",
        "# Validation triplets\n",
        "in_val_triplets = torch.stack([\n",
        "    torch.cat((in_val_tensor[i - gap], in_val_tensor[i + gap]))\n",
        "    for i in range(gap, len(in_val_tensor) - gap)\n",
        "])\n",
        "out_val_targets = out_val_tensor[gap : len(out_val_tensor) - gap]"
      ],
      "metadata": {
        "id": "ulNDtsp_qKXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some necessary functions for triplet interpolation\n",
        "# Function for performing inverse transform to predictions to get physical values\n",
        "def inv_log_scaled(values, scaler):\n",
        "    real_val = scaler.inverse_transform(np.array(values).reshape(-1, 1)).flatten()\n",
        "    physical_val = 10**real_val\n",
        "    return physical_val\n",
        "\n",
        "# Get triplet indices\n",
        "def get_interpolation_indices(center_index, data_length, gap):\n",
        "    idx1 = center_index - gap\n",
        "    idx3 = center_index + gap\n",
        "    if idx1 < 0 or idx3 >= data_length:\n",
        "        return None\n",
        "    return idx1, center_index, idx3\n",
        "\n",
        "# Function to load activation from string\n",
        "def load_activation_fn(activation_str):\n",
        "    activation_map = {\n",
        "        \"ReLU\": nn.ReLU,\n",
        "        \"LeakyReLU\": nn.LeakyReLU,\n",
        "        \"SiLU\": nn.SiLU\n",
        "    }\n",
        "\n",
        "    if \"LeakyReLU\" in activation_str:\n",
        "        return activation_map[\"LeakyReLU\"]\n",
        "    elif \"ReLU\" in activation_str:\n",
        "        return activation_map[\"ReLU\"]\n",
        "    elif \"SiLU\" in activation_str:\n",
        "        return activation_map[\"SiLU\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Activation function '{activation_str}' not recognized.\")"
      ],
      "metadata": {
        "id": "K_NFbClXsaOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_path = \"/content/drive/My Drive/Colab Notebooks/Random/top1\"\n",
        "output_dir  = os.path.join(top_path, \"InterpolationTriplet_Training\")\n",
        "config_path = os.path.join(top_path, \"config.json\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(config_path, \"r\") as f:\n",
        "    top1_config = json.load(f)\n",
        "hidden_sizes  = top1_config.get(\"hidden_layer_sizes\")\n",
        "dropout  = top1_config.get(\"dropout\")\n",
        "activation_str  = top1_config.get(\"activation_fn\")\n",
        "activation_fn  = load_activation_fn(activation_str)\n",
        "\n",
        "lr = 0.00012742749857031334\n",
        "\n",
        "\n",
        "input_triplet = 4 # concate x1, x3 = [T1, nb1, T3, nb3]\n",
        "output_triplet = 2 # P, S\n",
        "\n",
        "# Instantiate the model, without  previous weights just hiperparameters !!!\n",
        "triplet_model = Interpolation(in_size = input_triplet,\n",
        "                              out_size = output_triplet,\n",
        "                              hidden_layer_sizes=hidden_sizes,\n",
        "                              dropout=dropout,\n",
        "                              activation=activation_fn).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(triplet_model.parameters(), lr)"
      ],
      "metadata": {
        "id": "PAi4h9efkG6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_triplet_model(model, in_train, out_train, in_val, out_val,\n",
        "                        criterion, optimizer, device, epochs, save_path):\n",
        "    best_val_loss = float(\"inf\")\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        preds_train = model(in_train.to(device))\n",
        "        loss_train = criterion(preds_train, out_train.to(device))\n",
        "\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            preds_val = model(in_val.to(device))\n",
        "            loss_val = criterion(preds_val, out_val.to(device))\n",
        "\n",
        "        train_losses.append(loss_train.item())\n",
        "        val_losses.append(loss_val.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1:03d} | Train Loss: {loss_train.item():.5e} | Val Loss: {loss_val.item():.5e}\")\n",
        "\n",
        "        if loss_val.item() < best_val_loss:\n",
        "            best_val_loss = loss_val.item()\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"  ✅ Best model saved (val_loss = {best_val_loss:.5e})\")\n",
        "\n",
        "    return train_losses, val_losses"
      ],
      "metadata": {
        "id": "f0GFdcuDqN8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path  = os.path.join(output_dir, \"best_triplet_model.pth\")\n",
        "\n",
        "train_losses, val_losses = train_triplet_model(\n",
        "    model=triplet_model,\n",
        "    in_train=in_train_triplets,\n",
        "    out_train=out_train_targets,\n",
        "    in_val=in_val_triplets,\n",
        "    out_val=out_val_targets,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=150,\n",
        "    save_path=save_path\n",
        ")\n",
        "\n",
        "losses_df = pd.DataFrame({\n",
        "    \"epoch\": list(range(1, len(train_losses) + 1)),\n",
        "    \"train_loss\": train_losses,\n",
        "    \"val_loss\": val_losses\n",
        "})\n",
        "\n",
        "losses_csv_path = os.path.join(output_dir, \"triplet_model_losses.csv\")\n",
        "losses_df.to_csv(losses_csv_path, index=False)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses_df[\"epoch\"], losses_df[\"train_loss\"], label=\"Train Loss\", linewidth=2)\n",
        "plt.plot(losses_df[\"epoch\"], losses_df[\"val_loss\"], label=\"Validation Loss\", linewidth=2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss (MSE)\")\n",
        "plt.title(\"TripletNet Training and Validation Loss\")\n",
        "plt.yscale(\"log\")  # log scale is useful if loss varies a lot\n",
        "plt.grid(True, which='both', linestyle='--', alpha=0.5)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, \"triplet_model_loss_curve.png\"), dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QqcZIebqmcBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NN and B-SPlines Interpolation"
      ],
      "metadata": {
        "id": "dENyCvbnj4xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #######################################################\n",
        "# INTERPOLATION FOR THE TRIPLET\n",
        "# #######################################################\n",
        "def Interpolation_Triplet_test(model, inputs_set, outputs_set, scaler_P, scaler_S, device, indices, save_dir, gap):\n",
        "    model.eval()\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    metrics = []\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    for i, center_index in enumerate(indices):\n",
        "        idx1, idx2, idx3 = get_interpolation_indices(center_index, len(inputs_set), gap)\n",
        "\n",
        "        if idx1 is None:\n",
        "            print(f\"Saltando índice {center_index} (gap={gap}) debido a límites.\")\n",
        "            continue\n",
        "\n",
        "        x1 = inputs_set[idx1]\n",
        "        x3 = inputs_set[idx3]\n",
        "\n",
        "        y1 = outputs_set[idx1]\n",
        "        y2_true = outputs_set[idx2]\n",
        "        y3 = outputs_set[idx3]\n",
        "\n",
        "        # Concatenate x1 y x3 for input in the Interpolation NN\n",
        "        triplet_input_tensor = torch.cat([\n",
        "            torch.FloatTensor(x1).unsqueeze(0),\n",
        "            torch.FloatTensor(x3).unsqueeze(0)\n",
        "        ], dim=1).to(device)\n",
        "\n",
        "        # Real outputs\n",
        "        P_true = 10 ** np.array([y1[0], y2_true[0], y3[0]])\n",
        "        S_true = 10 ** np.array([y1[1], y2_true[1], y3[1]])\n",
        "\n",
        "        # Predictions\n",
        "        with torch.no_grad():\n",
        "            y2_pred_scaled = model(triplet_input_tensor).cpu().numpy()[0]\n",
        "\n",
        "        P2_pred = inv_log_scaled(y2_pred_scaled[0], scaler_P)\n",
        "        S2_pred = inv_log_scaled(y2_pred_scaled[1], scaler_S)\n",
        "\n",
        "        # Metrics\n",
        "        mse_P = mean_squared_error([P_true[1]], [P2_pred])\n",
        "        mae_P = mean_absolute_error([P_true[1]], [P2_pred])\n",
        "        mse_S = mean_squared_error([S_true[1]], [S2_pred])\n",
        "        mae_S = mean_absolute_error([S_true[1]], [S2_pred])\n",
        "\n",
        "        metrics.append({\n",
        "            \"method\": \"TripletNet\", \"index\": int(center_index), \"gap\": gap,\n",
        "            \"mse_P\": mse_P, \"mae_P\": mae_P,\n",
        "            \"mse_S\": mse_S, \"mae_S\": mae_S\n",
        "        })\n",
        "\n",
        "        # Interpolation graph\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        x_labels_plot = [f'Idx {idx1}', f'Idx {idx2}', f'Idx {idx3}']\n",
        "        x_ticks = np.arange(3)\n",
        "\n",
        "        axs[0].plot(x_ticks, P_true, label='True P', marker='o', color='green')\n",
        "        axs[0].scatter(x_ticks[1], P2_pred, label='Predicted P', marker='x', s=100, color='red')\n",
        "        axs[0].set_title('Pressure (P) [MeV/fm³]')\n",
        "        axs[0].set_xticks(x_ticks)\n",
        "        axs[0].set_xticklabels(x_labels_plot)\n",
        "        axs[0].grid(True)\n",
        "        axs[0].legend()\n",
        "        axs[0].ticklabel_format(axis='y', style='sci', scilimits=(-3, 3))\n",
        "\n",
        "        axs[1].plot(x_ticks, S_true, label='True S', marker='o', color='blue')\n",
        "        axs[1].scatter(x_ticks[1], S2_pred, label='Predicted S', marker='x', s=100, color='orange')\n",
        "        axs[1].set_title('Entropy (S) [1/fm³]')\n",
        "        axs[1].set_xticks(x_ticks)\n",
        "        axs[1].set_xticklabels(x_labels_plot)\n",
        "        axs[1].grid(True)\n",
        "        axs[1].legend()\n",
        "        axs[1].ticklabel_format(axis='y', style='sci', scilimits=(-3, 3))\n",
        "\n",
        "        plt.suptitle(f\"NN Interpolation Triplet Test #{i+1} (Index {center_index})\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        filename = f\"TripletNet_triplet_{i+1}_index_{center_index}_gap_{gap}.png\"\n",
        "        plt.savefig(os.path.join(save_dir, filename), dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "FLKUYggLd6Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "# b-SPLINES INTERPOLATION\n",
        "#######################################################\n",
        "def interpolation_test_bspline(in_train, out_train, in_test, out_test, indices, save_dir, gap):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    x = in_train[:, 0]\n",
        "    y = in_train[:, 1]\n",
        "    z_P = out_train[:, 0]\n",
        "    z_S = out_train[:, 1]\n",
        "\n",
        "    bspline_P = SmoothBivariateSpline(x, y, z_P, kx=3, ky=3)\n",
        "    bspline_S = SmoothBivariateSpline(x, y, z_S, kx=3, ky=3)\n",
        "\n",
        "    metrics = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, center_index in enumerate(indices):\n",
        "        idx1, idx2, idx3 = get_interpolation_indices(center_index, len(in_test), gap)\n",
        "\n",
        "        if idx1 is None:\n",
        "            print(f\"Saltando índice {center_index} (gap={gap}) debido a límites.\")\n",
        "            continue\n",
        "\n",
        "        x1 = in_test[idx1]\n",
        "        x2 = in_test[idx2]\n",
        "        x3 = in_test[idx3]\n",
        "\n",
        "        y1 = in_test[idx1]\n",
        "        y2_true = in_test[idx2]\n",
        "        y3 = in_test[idx3]\n",
        "\n",
        "        # Predicción en el centro\n",
        "        P_pred_log = bspline_P.ev(x2[0], x2[1])\n",
        "        S_pred_log = bspline_S.ev(x2[0], x2[1])\n",
        "\n",
        "        # Valores verdaderos en el triplete (ya están en log10, los destransformamos)\n",
        "        P_true = 10 ** np.array([y1[0], y2_true[0], y3[0]])\n",
        "        S_true = 10 ** np.array([y1[1], y2_true[1], y3[1]])\n",
        "        P_pred = 10 ** P_pred_log\n",
        "        S_pred = 10 ** S_pred_log\n",
        "\n",
        "        # Métricas\n",
        "        mse_P = mean_squared_error([P_true[1]], [P_pred])\n",
        "        mae_P = mean_absolute_error([P_true[1]], [P_pred])\n",
        "        mse_S = mean_squared_error([S_true[1]], [S_pred])\n",
        "        mae_S = mean_absolute_error([S_true[1]], [S_pred])\n",
        "\n",
        "        metrics.append({\n",
        "            \"method\": \"B-Spline\",\n",
        "            \"index\": int(center_index),\n",
        "            \"mse_P\": mse_P,\n",
        "            \"mae_P\": mae_P,\n",
        "            \"mse_S\": mse_S,\n",
        "            \"mae_S\": mae_S\n",
        "        })\n",
        "\n",
        "        # === Plot (idéntico al de NN) ===\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        x_labels_plot = [f'Idx {idx1}', f'Idx {idx2}', f'Idx {idx3}']\n",
        "        x_ticks = np.arange(3)\n",
        "\n",
        "        axs[0].plot(x_ticks, P_true, label='True P', marker='o', color='green')\n",
        "        axs[0].scatter(x_ticks[1], P_pred, label='Predicted P', marker='x', s=100, color='red')\n",
        "        axs[0].set_title('Pressure (P) [MeV/fm³]')\n",
        "        axs[0].set_xticks(x_ticks)\n",
        "        axs[0].set_xticklabels(x_labels_plot)\n",
        "        axs[0].grid(True)\n",
        "        axs[0].legend()\n",
        "        axs[0].ticklabel_format(axis='y', style='sci', scilimits=(-3, 3)) # Scientific notation for y-axis\n",
        "\n",
        "        axs[1].plot(x_ticks, S_true, label='True S', marker='o', color='blue')\n",
        "        axs[1].scatter(x_ticks[1], S_pred, label='Predicted S', marker='x', s=100, color='orange')\n",
        "        axs[1].set_title('Entropy (S) [1/fm³]')\n",
        "        axs[1].set_xticks(x_ticks)\n",
        "        axs[1].set_xticklabels(x_labels_plot)\n",
        "        axs[1].grid(True)\n",
        "        axs[1].legend()\n",
        "        axs[0].ticklabel_format(axis='y', style='sci', scilimits=(-3, 3)) # Scientific notation for y-axis\n",
        "\n",
        "        plt.suptitle(f\"B-Spline Interpolation Triplet Test #{i+1} (Index {center_index})\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        filename = f\"SPLINE_triplet_{i+1}_index_{center_index}.png\"\n",
        "        plt.savefig(os.path.join(save_dir, filename), dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    for m in metrics:\n",
        "        m[\"elapsed_sec\"] = elapsed\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "YG6qU9XuvcQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the top1 model hyperparameteres\n",
        "output_dir  = \"/content/drive/My Drive/Colab Notebooks/Random/top1/InterpolationTriplet_Training\"\n",
        "best_model_path = os.path.join(output_dir , \"best_triplet_model.pth\")\n",
        "\n",
        "triplet_model.load_state_dict(torch.load(best_model_path))\n",
        "triplet_model.eval()\n",
        "\n",
        "# Define indices\n",
        "N_test_samples = len(in_test_processed)\n",
        "np.random.seed(42)\n",
        "max_gap_for_test_selection = 10\n",
        "indices = np.sort(np.random.randint(max_gap_for_test_selection, N_test_samples - max_gap_for_test_selection, size=5))\n",
        "print(f\"Indices for InterpolationTripletNe from test data set: {indices}\")\n",
        "\n",
        "# Define saving directory\n",
        "triplet_nn_save_base_dir = os.path.join(output_dir, \"TripletNet_Interpolation_Tests\")\n",
        "os.makedirs(triplet_nn_save_base_dir, exist_ok=True)\n",
        "\n",
        "for current_gap in [1, 5, 10]:\n",
        "    print(f\"\\n▶️ TripletNet and B-Spline with gap={current_gap}...\")\n",
        "\n",
        "    save_dir_gap = os.path.join(triplet_nn_save_base_dir, f\"gap_{current_gap}\")\n",
        "    os.makedirs(save_dir_gap, exist_ok=True)\n",
        "\n",
        "    # === Interpolación con TripletNet ===\n",
        "    t0 = time.time()\n",
        "    metrics_triplet_nn_gap = Interpolation_Triplet_test(\n",
        "        model=triplet_model,\n",
        "        inputs_set=in_test,\n",
        "        outputs_set=out_test,\n",
        "        scaler_P=scaler_P,\n",
        "        scaler_S=scaler_S,\n",
        "        device=device,\n",
        "        indices=indices,\n",
        "        save_dir=save_dir_gap,\n",
        "        gap=current_gap\n",
        "    )\n",
        "    elapsed_nn = time.time() - t0\n",
        "\n",
        "    for metric in metrics_triplet_nn_gap:\n",
        "        metric[\"time_sec\"] = elapsed_nn\n",
        "        print(f\"NN: {metric}\")\n",
        "    df_nn = pd.DataFrame(metrics_triplet_nn_gap)\n",
        "\n",
        "    # === Interpolación con B-Spline ===\n",
        "    t1 = time.time()\n",
        "    metrics_spline_gap = interpolation_test_bspline(\n",
        "        in_train=in_train,\n",
        "        out_train=out_train,\n",
        "        in_test=in_test,\n",
        "        out_test=out_test,\n",
        "        indices=indices,\n",
        "        save_dir=save_dir_gap,\n",
        "        gap=current_gap\n",
        "    )\n",
        "    elapsed_spline = time.time() - t1\n",
        "\n",
        "    for metric in metrics_spline_gap:\n",
        "        metric[\"time_sec\"] = elapsed_spline\n",
        "        print(f\"SPLINE: {metric}\")\n",
        "    df_spline = pd.DataFrame(metrics_spline_gap)\n",
        "\n",
        "    df_all = pd.concat([df_nn, df_spline], ignore_index=True)\n",
        "    csv_path = os.path.join(save_dir_gap, f\"metrics_triplet_gap_{current_gap}.csv\")\n",
        "    df_all.to_csv(csv_path, index=False)"
      ],
      "metadata": {
        "id": "0v9r8v3M0Jcs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "w-w8OGEIEjpa",
        "EmbviN_LEDIl",
        "Juq6pWTCEF-G",
        "4MF1X6L8Khs4",
        "chvUlGvsEmsr",
        "UP7hdEKMwABJ",
        "0H6K5b2h-ztb",
        "eb3q75CSE8rG",
        "epZ2G4d9pIcr",
        "I3ovVc3-pO-T",
        "_Kb_ALprfrxw",
        "ZWrSUFjmflDK",
        "5xARTwgmEuhj",
        "MLsVgqWGToAI",
        "XVH70u0qMj1J",
        "C_Q3XlrkkAFq",
        "9tJMll1ikC8N",
        "dENyCvbnj4xb",
        "BAA4Z78_vZYU",
        "EzRIHNOP0A3G"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}